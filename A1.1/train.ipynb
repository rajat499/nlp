{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rajat499/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rajat499/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from util import preprocess, convert_class\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    filename = sys.argv[1]\n",
    "    model_path = sys.argv[2]\n",
    "    \n",
    "    train = pd.read_csv(filename)\n",
    "    train = preprocess(train, 'Subject')\n",
    "    train = preprocess(train, \"Content\")\n",
    "    df = convert_class(train)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer().fit(df[\"Subject\"] + \" \" + df[\"Content\"])\n",
    "    X_train = vectorizer.transform(df[\"Subject\"]+\" \"+df[\"Content\"])\n",
    "    \n",
    "    vect_path = \"vectorizer.pkl\"  \n",
    "    with open(vect_path, 'wb') as file:  \n",
    "        pickle.dump(vectorizer, file)\n",
    "        \n",
    "    clf = BaggingClassifier(base_estimator=SGDClassifier(), random_state=3, n_estimators=12, n_jobs=-3)\n",
    "    clf = clf.fit(X_train, df.Class)\n",
    "    \n",
    "    pred = clf.predict(X_train)\n",
    "    mat = confusion_matrix(pred, df.Class)\n",
    "    total = 0\n",
    "    for i in range(mat.shape[0]):\n",
    "        total += mat[i][i]/sum(mat[i])\n",
    "\n",
    "    print(\"Micro Accuraccy: \", total/mat.shape[0]) \n",
    "    print(\"Macro Accuracy: \", np.mean(pred == df.Class))\n",
    "    \n",
    "    with open(model_path, 'wb') as file:  \n",
    "        pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Micro Accuraccy:  0.8746211250457631 Macro Accuracy:  0.8097345132743363\n",
      "2 Micro Accuraccy:  0.8152716480395815 Macro Accuracy:  0.8230088495575221\n",
      "3 Micro Accuraccy:  0.8368728041390907 Macro Accuracy:  0.8362831858407079\n",
      "4 Micro Accuraccy:  0.8601392071980306 Macro Accuracy:  0.8451327433628318\n",
      "5 Micro Accuraccy:  0.8620629370629371 Macro Accuracy:  0.8407079646017699\n",
      "6 Micro Accuraccy:  0.8596505758889197 Macro Accuracy:  0.8407079646017699\n",
      "7 Micro Accuraccy:  0.8444533998398168 Macro Accuracy:  0.831858407079646\n",
      "8 Micro Accuraccy:  0.8429364907268354 Macro Accuracy:  0.827433628318584\n",
      "9 Micro Accuraccy:  0.8542785398122478 Macro Accuracy:  0.831858407079646\n",
      "10 Micro Accuraccy:  0.8466895658062229 Macro Accuracy:  0.831858407079646\n",
      "11 Micro Accuraccy:  0.8422151618872931 Macro Accuracy:  0.827433628318584\n",
      "12 Micro Accuraccy:  0.8457209457209457 Macro Accuracy:  0.827433628318584\n",
      "13 Micro Accuraccy:  0.8354919556956908 Macro Accuracy:  0.8097345132743363\n",
      "14 Micro Accuraccy:  0.840365810530518 Macro Accuracy:  0.8097345132743363\n",
      "15 Micro Accuraccy:  0.8350378063803577 Macro Accuracy:  0.8097345132743363\n",
      "16 Micro Accuraccy:  0.8381649424022305 Macro Accuracy:  0.8185840707964602\n",
      "17 Micro Accuraccy:  0.8440546667130073 Macro Accuracy:  0.8230088495575221\n",
      "18 Micro Accuraccy:  0.8509455456823877 Macro Accuracy:  0.827433628318584\n",
      "19 Micro Accuraccy:  0.8509455456823877 Macro Accuracy:  0.827433628318584\n",
      "20 Micro Accuraccy:  0.8500381046660538 Macro Accuracy:  0.827433628318584\n",
      "21 Micro Accuraccy:  0.8524430532076205 Macro Accuracy:  0.831858407079646\n",
      "22 Micro Accuraccy:  0.842791565778854 Macro Accuracy:  0.8185840707964602\n",
      "23 Micro Accuraccy:  0.8403978696741854 Macro Accuracy:  0.8141592920353983\n",
      "24 Micro Accuraccy:  0.8498841273473906 Macro Accuracy:  0.8230088495575221\n",
      "25 Micro Accuraccy:  0.8513459203453736 Macro Accuracy:  0.827433628318584\n",
      "26 Micro Accuraccy:  0.8498841273473906 Macro Accuracy:  0.8230088495575221\n",
      "27 Micro Accuraccy:  0.844038534696723 Macro Accuracy:  0.8141592920353983\n",
      "28 Micro Accuraccy:  0.8548606107907846 Macro Accuracy:  0.827433628318584\n",
      "29 Micro Accuraccy:  0.8484338699940891 Macro Accuracy:  0.8185840707964602\n",
      "30 Micro Accuraccy:  0.8411461624761243 Macro Accuracy:  0.8053097345132744\n",
      "31 Micro Accuraccy:  0.8479265983367764 Macro Accuracy:  0.8141592920353983\n",
      "32 Micro Accuraccy:  0.8459329779221033 Macro Accuracy:  0.8141592920353983\n",
      "33 Micro Accuraccy:  0.8504274904087622 Macro Accuracy:  0.8185840707964602\n",
      "34 Micro Accuraccy:  0.8423310342462645 Macro Accuracy:  0.8097345132743363\n",
      "35 Micro Accuraccy:  0.8489874290730117 Macro Accuracy:  0.8141592920353983\n",
      "36 Micro Accuraccy:  0.8500869520740626 Macro Accuracy:  0.8141592920353983\n",
      "37 Micro Accuraccy:  0.8489874290730117 Macro Accuracy:  0.8141592920353983\n",
      "38 Micro Accuraccy:  0.8475562072336267 Macro Accuracy:  0.8097345132743363\n",
      "39 Micro Accuraccy:  0.8421039859489399 Macro Accuracy:  0.8097345132743363\n",
      "40 Micro Accuraccy:  0.8447072294796028 Macro Accuracy:  0.8097345132743363\n",
      "41 Micro Accuraccy:  0.8318957115009747 Macro Accuracy:  0.7964601769911505\n",
      "42 Micro Accuraccy:  0.8157445167724823 Macro Accuracy:  0.7920353982300885\n",
      "43 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "44 Micro Accuraccy:  0.8351914569741395 Macro Accuracy:  0.7964601769911505\n",
      "45 Micro Accuraccy:  0.8351914569741395 Macro Accuracy:  0.7964601769911505\n",
      "46 Micro Accuraccy:  0.8394627412454237 Macro Accuracy:  0.8008849557522124\n",
      "47 Micro Accuraccy:  0.8432554338136266 Macro Accuracy:  0.8053097345132744\n",
      "48 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "49 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "50 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "51 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "52 Micro Accuraccy:  0.8284635105283423 Macro Accuracy:  0.8097345132743363\n",
      "53 Micro Accuraccy:  0.8287188224657906 Macro Accuracy:  0.8097345132743363\n",
      "54 Micro Accuraccy:  0.8252748100471833 Macro Accuracy:  0.8053097345132744\n",
      "55 Micro Accuraccy:  0.8363599972152604 Macro Accuracy:  0.8008849557522124\n",
      "56 Micro Accuraccy:  0.8138935322743056 Macro Accuracy:  0.7964601769911505\n",
      "57 Micro Accuraccy:  0.8421039859489399 Macro Accuracy:  0.8097345132743363\n",
      "58 Micro Accuraccy:  0.8421039859489399 Macro Accuracy:  0.8097345132743363\n",
      "59 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "60 Micro Accuraccy:  0.8212052500813066 Macro Accuracy:  0.8008849557522124\n",
      "61 Micro Accuraccy:  0.8226715665165204 Macro Accuracy:  0.8053097345132744\n",
      "62 Micro Accuraccy:  0.819567067922331 Macro Accuracy:  0.8053097345132744\n",
      "63 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "64 Micro Accuraccy:  0.8206715061667892 Macro Accuracy:  0.8053097345132744\n",
      "65 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "66 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "67 Micro Accuraccy:  0.8416154021417179 Macro Accuracy:  0.8141592920353983\n",
      "68 Micro Accuraccy:  0.8361879045686779 Macro Accuracy:  0.8008849557522124\n",
      "69 Micro Accuraccy:  0.8387586592483499 Macro Accuracy:  0.8053097345132744\n",
      "70 Micro Accuraccy:  0.8401184463684463 Macro Accuracy:  0.8097345132743363\n",
      "71 Micro Accuraccy:  0.8375254626204166 Macro Accuracy:  0.8053097345132744\n",
      "72 Micro Accuraccy:  0.8416154021417179 Macro Accuracy:  0.8141592920353983\n",
      "73 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "74 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "75 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "76 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "77 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "78 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "79 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "80 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "81 Micro Accuraccy:  0.8389994873547505 Macro Accuracy:  0.8097345132743363\n",
      "82 Micro Accuraccy:  0.8562104562104561 Macro Accuracy:  0.827433628318584\n",
      "83 Micro Accuraccy:  0.8456486812156916 Macro Accuracy:  0.8141592920353983\n",
      "84 Micro Accuraccy:  0.8456486812156916 Macro Accuracy:  0.8141592920353983\n",
      "85 Micro Accuraccy:  0.8471878998194787 Macro Accuracy:  0.8185840707964602\n",
      "86 Micro Accuraccy:  0.8456486812156916 Macro Accuracy:  0.8141592920353983\n",
      "87 Micro Accuraccy:  0.849827477487052 Macro Accuracy:  0.8230088495575221\n",
      "88 Micro Accuraccy:  0.8538295038295038 Macro Accuracy:  0.8230088495575221\n",
      "89 Micro Accuraccy:  0.849827477487052 Macro Accuracy:  0.8230088495575221\n",
      "90 Micro Accuraccy:  0.8523482661731511 Macro Accuracy:  0.827433628318584\n",
      "91 Micro Accuraccy:  0.849827477487052 Macro Accuracy:  0.8230088495575221\n",
      "92 Micro Accuraccy:  0.8562104562104561 Macro Accuracy:  0.827433628318584\n",
      "93 Micro Accuraccy:  0.8471878998194787 Macro Accuracy:  0.8185840707964602\n",
      "94 Micro Accuraccy:  0.8485563778326937 Macro Accuracy:  0.8185840707964602\n",
      "95 Micro Accuraccy:  0.8413287053952015 Macro Accuracy:  0.8185840707964602\n",
      "96 Micro Accuraccy:  0.849827477487052 Macro Accuracy:  0.8230088495575221\n",
      "97 Micro Accuraccy:  0.8510527403194577 Macro Accuracy:  0.8230088495575221\n",
      "98 Micro Accuraccy:  0.8513587794693785 Macro Accuracy:  0.827433628318584\n",
      "99 Micro Accuraccy:  0.8540031397174254 Macro Accuracy:  0.8362831858407079\n",
      "100 Micro Accuraccy:  0.8433649146157319 Macro Accuracy:  0.8230088495575221\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "train = preprocess(train, 'Subject')\n",
    "train = preprocess(train, \"Content\")\n",
    "df = convert_class(train)\n",
    "\n",
    "val = pd.read_csv(\"val.csv\")\n",
    "val = preprocess(val, \"Subject\")\n",
    "val = preprocess(val, \"Content\")\n",
    "val = convert_class(val)\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3)).fit(df[\"Subject\"] + \" \" + df[\"Content\"])\n",
    "X_train = vectorizer.transform(df[\"Subject\"]+\" \"+df[\"Content\"])\n",
    "\n",
    "acc = {}\n",
    "for p in range(1, 101, 1):\n",
    "    select = SelectPercentile(percentile=p)\n",
    "    select.fit(X_train, df.Class)\n",
    "    tr = select.transform(X_train)\n",
    "\n",
    "    clf = BaggingClassifier(base_estimator=SGDClassifier(), random_state=3, n_estimators=12, n_jobs=-3)\n",
    "    clf = clf.fit(tr, df.Class)\n",
    "\n",
    "    X_val = select.transform(vectorizer.transform(val[\"Subject\"]+\" \"+val[\"Content\"]))\n",
    "\n",
    "    pred = clf.predict(X_val)\n",
    "    mat = confusion_matrix(pred, val.Class)\n",
    "    total = 0\n",
    "    for i in range(mat.shape[0]):\n",
    "        total += mat[i][i]/sum(mat[i])\n",
    "\n",
    "    print(p, \"Micro Accuraccy: \", total/mat.shape[0], \"Macro Accuracy: \", np.mean(pred == val.Class))\n",
    "    acc[p] = (total/mat.shape[0] + np.mean(pred == val.Class))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42, 0.8038899575012854),\n",
       " (56, 0.805176854632728),\n",
       " (60, 0.8110451029167596),\n",
       " (62, 0.8124384012178028),\n",
       " (64, 0.8129906203400318),\n",
       " (61, 0.8139906505148974),\n",
       " (41, 0.8141779442460626),\n",
       " (54, 0.8152922722802288),\n",
       " (44, 0.815825816982645),\n",
       " (45, 0.815825816982645),\n",
       " (68, 0.8185364301604452),\n",
       " (55, 0.8186224764837364),\n",
       " (52, 0.8190990119013393),\n",
       " (2, 0.8191402487985517),\n",
       " (53, 0.8192266678700635),\n",
       " (46, 0.8201738484988181),\n",
       " (43, 0.8214175985668455),\n",
       " (48, 0.8214175985668455),\n",
       " (49, 0.8214175985668455),\n",
       " (59, 0.8214175985668455),\n",
       " (66, 0.8214175985668455),\n",
       " (71, 0.8214175985668455),\n",
       " (69, 0.8220341968808121),\n",
       " (15, 0.822386159827347),\n",
       " (13, 0.8226132344850136),\n",
       " (30, 0.8232279484946994),\n",
       " (47, 0.8242825841634505),\n",
       " (50, 0.8243670003145434),\n",
       " (51, 0.8243670003145434),\n",
       " (63, 0.8243670003145434),\n",
       " (65, 0.8243670003145434),\n",
       " (73, 0.8243670003145434),\n",
       " (74, 0.8243670003145434),\n",
       " (75, 0.8243670003145434),\n",
       " (76, 0.8243670003145434),\n",
       " (77, 0.8243670003145434),\n",
       " (78, 0.8243670003145434),\n",
       " (79, 0.8243670003145434),\n",
       " (80, 0.8243670003145434),\n",
       " (81, 0.8243670003145434),\n",
       " (70, 0.8249264798213913),\n",
       " (14, 0.8250501619024271),\n",
       " (39, 0.8259192496116381),\n",
       " (57, 0.8259192496116381),\n",
       " (58, 0.8259192496116381),\n",
       " (34, 0.8260327737603004),\n",
       " (40, 0.8272208713769695),\n",
       " (23, 0.8272785808547918),\n",
       " (67, 0.8278873470885582),\n",
       " (72, 0.8278873470885582),\n",
       " (16, 0.8283745065993453),\n",
       " (38, 0.8286453602539815),\n",
       " (27, 0.8290989133660607),\n",
       " (83, 0.8299039866255449),\n",
       " (84, 0.8299039866255449),\n",
       " (86, 0.8299039866255449),\n",
       " (95, 0.8299563880958309),\n",
       " (32, 0.8300461349787508),\n",
       " (22, 0.8306878182876571),\n",
       " (31, 0.8310429451860873),\n",
       " (35, 0.831573360554205),\n",
       " (37, 0.831573360554205),\n",
       " (36, 0.8321231220547305),\n",
       " (85, 0.8328859853079695),\n",
       " (93, 0.8328859853079695),\n",
       " (100, 0.8331868820866271),\n",
       " (29, 0.8335089703952747),\n",
       " (17, 0.8335317581352647),\n",
       " (94, 0.833570224314577),\n",
       " (33, 0.8345057806026113),\n",
       " (11, 0.8348243951029386),\n",
       " (8, 0.8351850595227097),\n",
       " (87, 0.836418163522287),\n",
       " (89, 0.836418163522287),\n",
       " (91, 0.836418163522287),\n",
       " (96, 0.836418163522287),\n",
       " (24, 0.8364464884524563),\n",
       " (26, 0.8364464884524563),\n",
       " (12, 0.8365772870197649),\n",
       " (3, 0.8365779949898993),\n",
       " (97, 0.8370307949384899),\n",
       " (7, 0.8381559034597315),\n",
       " (88, 0.838419176693513),\n",
       " (20, 0.8387358664923189),\n",
       " (18, 0.8391895870004858),\n",
       " (19, 0.8391895870004858),\n",
       " (10, 0.8392739864429344),\n",
       " (25, 0.8393897743319788),\n",
       " (98, 0.8393962038939813),\n",
       " (90, 0.8398909472458675),\n",
       " (28, 0.8411471195546842),\n",
       " (82, 0.8418220422645201),\n",
       " (92, 0.8418220422645201),\n",
       " (21, 0.8421507301436333),\n",
       " (1, 0.8421778191600497),\n",
       " (9, 0.8430684734459468),\n",
       " (99, 0.8451431627790666),\n",
       " (6, 0.8501792702453448),\n",
       " (5, 0.8513854508323535),\n",
       " (4, 0.8526359752804312)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(acc.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
